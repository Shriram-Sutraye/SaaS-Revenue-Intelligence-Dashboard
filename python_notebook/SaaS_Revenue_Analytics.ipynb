{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c809ecb1-c3c5-41bb-a94a-afb19c12b156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Environment Configuration Complete\n",
      "======================================================================\n",
      "Analysis Date: 2025-10-23 20:03\n",
      "Pandas Version: 2.1.1\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SaaS Revenue Intelligence Analytics\n",
    "Data Engineering and Business Analysis Pipeline\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Environment Configuration Complete\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05d4676-1d29-4dd2-9863-ad61effb4820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Raw Dataset Loaded\n",
      "======================================================================\n",
      "Total Rows: 541,909\n",
      "Total Columns: 8\n",
      "Date Range: 2010-12-01 08:26:00 to 2011-12-09 12:50:00\n",
      "Memory Usage: 195.86 MB\n",
      "======================================================================\n",
      "\n",
      "First 5 Rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17,850.00</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17,850.00</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17,850.00</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17,850.00</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17,850.00</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "           InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0  2010-12-01 08:26:00       2.55   17,850.00  United Kingdom  \n",
       "1  2010-12-01 08:26:00       3.39   17,850.00  United Kingdom  \n",
       "2  2010-12-01 08:26:00       2.75   17,850.00  United Kingdom  \n",
       "3  2010-12-01 08:26:00       3.39   17,850.00  United Kingdom  \n",
       "4  2010-12-01 08:26:00       3.39   17,850.00  United Kingdom  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load UCI Online Retail dataset\n",
    "df_raw = pd.read_csv('Online_Retail.csv', encoding='ISO-8859-1')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Raw Dataset Loaded\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total Rows: {df_raw.shape[0]:,}\")\n",
    "print(f\"Total Columns: {df_raw.shape[1]}\")\n",
    "print(f\"Date Range: {pd.to_datetime(df_raw['InvoiceDate']).min()} to {pd.to_datetime(df_raw['InvoiceDate']).max()}\")\n",
    "print(f\"Memory Usage: {df_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b3810fd-05cc-4627-9dba-8c0dfefa1340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Dataset Structure\n",
      "======================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   InvoiceNo    541909 non-null  object \n",
      " 1   StockCode    541909 non-null  object \n",
      " 2   Description  540455 non-null  object \n",
      " 3   Quantity     541909 non-null  int64  \n",
      " 4   InvoiceDate  541909 non-null  object \n",
      " 5   UnitPrice    541909 non-null  float64\n",
      " 6   CustomerID   406829 non-null  float64\n",
      " 7   Country      541909 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 33.1+ MB\n",
      "\n",
      "======================================================================\n",
      "Statistical Summary\n",
      "======================================================================\n",
      "        Quantity  UnitPrice  CustomerID\n",
      "count 541,909.00 541,909.00  406,829.00\n",
      "mean        9.55       4.61   15,287.69\n",
      "std       218.08      96.76    1,713.60\n",
      "min   -80,995.00 -11,062.06   12,346.00\n",
      "25%         1.00       1.25   13,953.00\n",
      "50%         3.00       2.08   15,152.00\n",
      "75%        10.00       4.13   16,791.00\n",
      "max    80,995.00  38,970.00   18,287.00\n",
      "\n",
      "======================================================================\n",
      "Missing Values Analysis\n",
      "======================================================================\n",
      "                  Column  Missing_Count  Missing_Percentage\n",
      "CustomerID    CustomerID         135080               24.93\n",
      "Description  Description           1454                0.27\n",
      "InvoiceNo      InvoiceNo              0                0.00\n",
      "StockCode      StockCode              0                0.00\n",
      "Quantity        Quantity              0                0.00\n",
      "InvoiceDate  InvoiceDate              0                0.00\n",
      "UnitPrice      UnitPrice              0                0.00\n",
      "Country          Country              0                0.00\n"
     ]
    }
   ],
   "source": [
    "# Dataset structure and quality assessment\n",
    "print(\"=\"*70)\n",
    "print(\"Dataset Structure\")\n",
    "print(\"=\"*70)\n",
    "df_raw.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Statistical Summary\")\n",
    "print(\"=\"*70)\n",
    "print(df_raw.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Missing Values Analysis\")\n",
    "print(\"=\"*70)\n",
    "missing = pd.DataFrame({\n",
    "    'Column': df_raw.columns,\n",
    "    'Missing_Count': df_raw.isnull().sum(),\n",
    "    'Missing_Percentage': (df_raw.isnull().sum() / len(df_raw) * 100).round(2)\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e47106c4-411b-4687-9b1b-0212a8029bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Data Quality Issues Detected\n",
      "======================================================================\n",
      "Missing CustomerID: 135,080 rows (24.93%)\n",
      "Negative Quantities: 10,624 rows (1.96%)\n",
      "Invalid Prices (<=0): 2,517 rows (0.46%)\n",
      "Duplicate Rows: 5,268 (0.97%)\n",
      "\n",
      "======================================================================\n",
      "Sample of Problematic Data (Negative Quantities):\n",
      "======================================================================\n",
      "    InvoiceNo StockCode                      Description  Quantity  \\\n",
      "141   C536379         D                         Discount        -1   \n",
      "154   C536383    35004C  SET OF 3 COLOURED  FLYING DUCKS        -1   \n",
      "235   C536391     22556   PLASTERS IN TIN CIRCUS PARADE        -12   \n",
      "\n",
      "             InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "141  2010-12-01 09:41:00      27.50   14,527.00  United Kingdom  \n",
      "154  2010-12-01 09:49:00       4.65   15,311.00  United Kingdom  \n",
      "235  2010-12-01 10:24:00       1.65   17,548.00  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "# Identify data quality issues\n",
    "print(\"=\"*70)\n",
    "print(\"Data Quality Issues Detected\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Missing CustomerID\n",
    "missing_customers = df_raw['CustomerID'].isnull().sum()\n",
    "missing_pct = (missing_customers / len(df_raw)) * 100\n",
    "print(f\"Missing CustomerID: {missing_customers:,} rows ({missing_pct:.2f}%)\")\n",
    "\n",
    "# Negative Quantities (Returns/Cancellations)\n",
    "negative_qty = df_raw[df_raw['Quantity'] < 0]\n",
    "print(f\"Negative Quantities: {len(negative_qty):,} rows ({len(negative_qty)/len(df_raw)*100:.2f}%)\")\n",
    "\n",
    "# Zero or Negative Prices\n",
    "invalid_price = df_raw[df_raw['UnitPrice'] <= 0]\n",
    "print(f\"Invalid Prices (<=0): {len(invalid_price):,} rows ({len(invalid_price)/len(df_raw)*100:.2f}%)\")\n",
    "\n",
    "# Duplicates\n",
    "duplicates = df_raw.duplicated().sum()\n",
    "print(f\"Duplicate Rows: {duplicates:,} ({duplicates/len(df_raw)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Sample of Problematic Data (Negative Quantities):\")\n",
    "print(\"=\"*70)\n",
    "print(negative_qty.head(3))\n",
    "\n",
    "# Store original count\n",
    "original_count = len(df_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca7ad383-e54a-4186-bb42-630c4166f629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Starting Data Cleaning Process\n",
      "======================================================================\n",
      "Removed missing CustomerIDs: 135,080 rows\n",
      "Removed negative quantities: 8,905 rows\n",
      "Removed invalid prices: 40 rows\n",
      "Removed duplicates: 5,192 rows\n",
      "\n",
      "======================================================================\n",
      "Cleaning Summary\n",
      "======================================================================\n",
      "Original Dataset: 541,909 rows\n",
      "Cleaned Dataset: 392,692 rows\n",
      "Rows Removed: 149,217\n",
      "Retention Rate: 72.5%\n",
      "======================================================================\n",
      "\n",
      "Data cleaning completed successfully\n",
      "Clean dataset shape: (392692, 9)\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "print(\"=\"*70)\n",
    "print(\"Starting Data Cleaning Process\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df_raw.copy()\n",
    "\n",
    "# Step 1: Remove missing CustomerIDs\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean[df_clean['CustomerID'].notna()]\n",
    "after = len(df_clean)\n",
    "print(f\"Removed missing CustomerIDs: {before - after:,} rows\")\n",
    "\n",
    "# Step 2: Remove negative quantities\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean[df_clean['Quantity'] > 0]\n",
    "after = len(df_clean)\n",
    "print(f\"Removed negative quantities: {before - after:,} rows\")\n",
    "\n",
    "# Step 3: Remove invalid prices\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean[df_clean['UnitPrice'] > 0]\n",
    "after = len(df_clean)\n",
    "print(f\"Removed invalid prices: {before - after:,} rows\")\n",
    "\n",
    "# Step 4: Remove duplicates\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "after = len(df_clean)\n",
    "print(f\"Removed duplicates: {before - after:,} rows\")\n",
    "\n",
    "# Calculate retention rate\n",
    "retention_rate = (len(df_clean) / original_count) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Cleaning Summary\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Original Dataset: {original_count:,} rows\")\n",
    "print(f\"Cleaned Dataset: {len(df_clean):,} rows\")\n",
    "print(f\"Rows Removed: {original_count - len(df_clean):,}\")\n",
    "print(f\"Retention Rate: {retention_rate:.1f}%\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Convert date column\n",
    "df_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'])\n",
    "\n",
    "# Create Revenue column\n",
    "df_clean['Revenue'] = df_clean['Quantity'] * df_clean['UnitPrice']\n",
    "\n",
    "print(\"\\nData cleaning completed successfully\")\n",
    "print(f\"Clean dataset shape: {df_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dca347c-92d1-4ee5-a4cf-5c47e2c28f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SaaS Transformation: Aggregating to Monthly Subscriptions\n",
      "======================================================================\n",
      "Transaction-level records: 392,692\n",
      "Monthly subscription records: 13,054\n",
      "Unique customers: 4,338\n",
      "Date range: 2010-12-01 00:00:00 to 2011-12-01 00:00:00\n",
      "\n",
      "Sample of MRR data:\n",
      "   CustomerID      Month       MRR  Items_Purchased  Transaction_Count\n",
      "0   12,346.00 2011-01-01 77,183.60            74215                  1\n",
      "1   12,347.00 2010-12-01    711.79              319                 31\n",
      "2   12,347.00 2011-01-01    475.39              315                 29\n",
      "3   12,347.00 2011-04-01    636.25              483                 24\n",
      "4   12,347.00 2011-06-01    382.52              196                 18\n",
      "5   12,347.00 2011-08-01    584.91              277                 22\n",
      "6   12,347.00 2011-10-01  1,294.32              676                 47\n",
      "7   12,347.00 2011-12-01    224.82              192                 11\n",
      "8   12,348.00 2010-12-01    892.80             1254                 17\n",
      "9   12,348.00 2011-01-01    227.44              601                  6\n"
     ]
    }
   ],
   "source": [
    "# Transform transactions to SaaS subscription model\n",
    "print(\"=\"*70)\n",
    "print(\"SaaS Transformation: Aggregating to Monthly Subscriptions\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Extract year-month from invoice date\n",
    "df_clean['YearMonth'] = df_clean['InvoiceDate'].dt.to_period('M')\n",
    "\n",
    "# Aggregate to monthly customer level (MRR - Monthly Recurring Revenue)\n",
    "mrr_data = df_clean.groupby(['CustomerID', 'YearMonth']).agg({\n",
    "    'Revenue': 'sum',\n",
    "    'Quantity': 'sum',\n",
    "    'InvoiceNo': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "mrr_data.columns = ['CustomerID', 'Month', 'MRR', 'Items_Purchased', 'Transaction_Count']\n",
    "\n",
    "# Convert period back to timestamp for easier handling\n",
    "mrr_data['Month'] = mrr_data['Month'].dt.to_timestamp()\n",
    "\n",
    "print(f\"Transaction-level records: {len(df_clean):,}\")\n",
    "print(f\"Monthly subscription records: {len(mrr_data):,}\")\n",
    "print(f\"Unique customers: {mrr_data['CustomerID'].nunique():,}\")\n",
    "print(f\"Date range: {mrr_data['Month'].min()} to {mrr_data['Month'].max()}\")\n",
    "\n",
    "print(\"\\nSample of MRR data:\")\n",
    "print(mrr_data.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24842779-ebc6-41bf-b70f-2e8e54324bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Calculating Customer Lifetime Metrics\n",
      "======================================================================\n",
      "Total customers analyzed: 4,338\n",
      "\n",
      "Customer Lifetime Metrics:\n",
      "       CustomerID                 First_Purchase  \\\n",
      "count    4,338.00                           4338   \n",
      "mean    15,300.41  2011-04-30 17:06:50.857538048   \n",
      "min     12,346.00            2010-12-01 08:26:00   \n",
      "25%     13,813.25            2011-01-17 11:13:15   \n",
      "50%     15,299.50            2011-04-05 09:52:30   \n",
      "75%     16,778.75            2011-08-19 10:11:30   \n",
      "max     18,287.00            2011-12-09 12:16:00   \n",
      "std      1,721.81                            NaN   \n",
      "\n",
      "                       Last_Purchase  Total_Orders  Total_Revenue  \\\n",
      "count                           4338      4,338.00       4,338.00   \n",
      "mean   2011-09-08 11:38:59.045643008          4.27       2,048.69   \n",
      "min              2010-12-01 09:53:00          1.00           3.75   \n",
      "25%              2011-07-20 19:18:00          1.00         306.48   \n",
      "50%              2011-10-20 10:40:30          2.00         668.57   \n",
      "75%              2011-11-22 11:05:45          5.00       1,660.60   \n",
      "max              2011-12-09 12:50:00        209.00     280,206.02   \n",
      "std                              NaN          7.70       8,985.23   \n",
      "\n",
      "       Total_Items  Lifetime_Days  Avg_Order_Value  \n",
      "count     4,338.00       4,338.00         4,338.00  \n",
      "mean      1,187.64         130.45           417.65  \n",
      "min           1.00           0.00             3.45  \n",
      "25%         159.00           0.00           177.87  \n",
      "50%         378.00          92.50           291.94  \n",
      "75%         989.75         251.75           428.28  \n",
      "max     196,915.00         373.00        84,236.25  \n",
      "std       5,043.62         132.04         1,796.51  \n",
      "\n",
      "Top 10 Customers by Revenue:\n",
      "      CustomerID  Total_Revenue  Total_Orders\n",
      "1689   14,646.00     280,206.02            73\n",
      "4201   18,102.00     259,657.30            60\n",
      "3728   17,450.00     194,390.79            46\n",
      "3008   16,446.00     168,472.50             2\n",
      "1879   14,911.00     143,711.17           201\n",
      "55     12,415.00     124,914.53            21\n",
      "1333   14,156.00     117,210.08            55\n",
      "3771   17,511.00      91,062.38            31\n",
      "2702   16,029.00      80,850.84            63\n",
      "0      12,346.00      77,183.60             1\n"
     ]
    }
   ],
   "source": [
    "# Calculate customer-level aggregated metrics\n",
    "print(\"=\"*70)\n",
    "print(\"Calculating Customer Lifetime Metrics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "customer_summary = df_clean.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': ['min', 'max'],\n",
    "    'InvoiceNo': 'nunique',\n",
    "    'Revenue': 'sum',\n",
    "    'Quantity': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "customer_summary.columns = ['CustomerID', 'First_Purchase', 'Last_Purchase', \n",
    "                            'Total_Orders', 'Total_Revenue', 'Total_Items']\n",
    "\n",
    "# Calculate customer lifetime in days\n",
    "customer_summary['Lifetime_Days'] = (customer_summary['Last_Purchase'] - \n",
    "                                      customer_summary['First_Purchase']).dt.days\n",
    "\n",
    "# Calculate average order value\n",
    "customer_summary['Avg_Order_Value'] = customer_summary['Total_Revenue'] / customer_summary['Total_Orders']\n",
    "\n",
    "print(f\"Total customers analyzed: {len(customer_summary):,}\")\n",
    "print(\"\\nCustomer Lifetime Metrics:\")\n",
    "print(customer_summary.describe())\n",
    "\n",
    "print(\"\\nTop 10 Customers by Revenue:\")\n",
    "print(customer_summary.nlargest(10, 'Total_Revenue')[['CustomerID', 'Total_Revenue', 'Total_Orders']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3bd70c-f0a5-4d25-a0f0-cc1da28b8713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RFM Analysis: Customer Segmentation\n",
      "======================================================================\n",
      "RFM Metrics Summary:\n",
      "       Recency  Frequency   Monetary\n",
      "count 4,338.00   4,338.00   4,338.00\n",
      "mean     92.54       4.27   2,048.69\n",
      "std     100.01       7.70   8,985.23\n",
      "min       1.00       1.00       3.75\n",
      "25%      18.00       1.00     306.48\n",
      "50%      51.00       2.00     668.57\n",
      "75%     142.00       5.00   1,660.60\n",
      "max     374.00     209.00 280,206.02\n",
      "\n",
      "Sample RFM Scores:\n",
      "   CustomerID  Recency  Frequency  Monetary R_Score F_Score M_Score RFM_Score  \\\n",
      "0   12,346.00      326          1 77,183.60       1       1       5       115   \n",
      "1   12,347.00        2          7  4,310.00       5       5       5       555   \n",
      "2   12,348.00       75          4  1,797.24       2       4       4       244   \n",
      "3   12,349.00       19          1  1,757.55       4       1       4       414   \n",
      "4   12,350.00      310          1    334.40       1       1       2       112   \n",
      "5   12,352.00       36          8  2,506.04       3       5       5       355   \n",
      "6   12,353.00      204          1     89.00       1       1       1       111   \n",
      "7   12,354.00      232          1  1,079.40       1       1       4       114   \n",
      "8   12,355.00      214          1    459.40       1       1       2       112   \n",
      "9   12,356.00       23          3  2,811.43       4       3       5       435   \n",
      "\n",
      "   RFM_Total  \n",
      "0          7  \n",
      "1         15  \n",
      "2         10  \n",
      "3          9  \n",
      "4          4  \n",
      "5         13  \n",
      "6          3  \n",
      "7          6  \n",
      "8          4  \n",
      "9         12  \n"
     ]
    }
   ],
   "source": [
    "# RFM Segmentation\n",
    "print(\"=\"*70)\n",
    "print(\"RFM Analysis: Customer Segmentation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define analysis date (day after last transaction)\n",
    "analysis_date = df_clean['InvoiceDate'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "# Calculate RFM metrics\n",
    "rfm = df_clean.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': lambda x: (analysis_date - x.max()).days,  # Recency\n",
    "    'InvoiceNo': 'nunique',  # Frequency\n",
    "    'Revenue': 'sum'  # Monetary\n",
    "}).reset_index()\n",
    "\n",
    "rfm.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "# Create RFM scores (1-5 scale, higher is better)\n",
    "rfm['R_Score'] = pd.qcut(rfm['Recency'], 5, labels=[5, 4, 3, 2, 1])\n",
    "rfm['F_Score'] = pd.qcut(rfm['Frequency'].rank(method='first'), 5, labels=[1, 2, 3, 4, 5])\n",
    "rfm['M_Score'] = pd.qcut(rfm['Monetary'], 5, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Combine scores\n",
    "rfm['RFM_Score'] = rfm['R_Score'].astype(str) + rfm['F_Score'].astype(str) + rfm['M_Score'].astype(str)\n",
    "rfm['RFM_Total'] = rfm['R_Score'].astype(int) + rfm['F_Score'].astype(int) + rfm['M_Score'].astype(int)\n",
    "\n",
    "print(\"RFM Metrics Summary:\")\n",
    "print(rfm[['Recency', 'Frequency', 'Monetary']].describe())\n",
    "\n",
    "print(\"\\nSample RFM Scores:\")\n",
    "print(rfm.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ac5d3e5-6c3e-49ab-b414-27c7152160a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Customer Segmentation Based on RFM\n",
      "======================================================================\n",
      "\n",
      "Customer Segment Distribution:\n",
      "Segment\n",
      "Lost               1065\n",
      "Champions           957\n",
      "Loyal Customers     764\n",
      "Need Attention      475\n",
      "Others              424\n",
      "Promising           250\n",
      "New Customers       235\n",
      "At Risk             168\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Segment Performance Metrics:\n",
      "                CustomerID     Monetary          Frequency Recency\n",
      "                     count          sum     mean      mean    mean\n",
      "Segment                                                           \n",
      "At Risk                168   370,498.85 2,205.35      5.53  125.56\n",
      "Champions              957 5,791,640.74 6,051.87     11.12   12.82\n",
      "Lost                  1065   518,322.15   486.69      1.10  217.90\n",
      "Loyal Customers        764 1,396,513.16 1,827.90      4.12   35.69\n",
      "Need Attention         475   427,553.66   900.11      2.65  162.49\n",
      "New Customers          235    56,697.16   241.26      1.12   18.77\n",
      "Others                 424   262,795.78   619.80      2.01   32.56\n",
      "Promising              250    63,187.39   252.75      1.07   53.33\n"
     ]
    }
   ],
   "source": [
    "# Segment customers based on RFM scores\n",
    "print(\"=\"*70)\n",
    "print(\"Customer Segmentation Based on RFM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def segment_customers(row):\n",
    "    r, f, m = int(row['R_Score']), int(row['F_Score']), int(row['M_Score'])\n",
    "    \n",
    "    if r >= 4 and f >= 4 and m >= 4:\n",
    "        return 'Champions'\n",
    "    elif r >= 3 and f >= 3 and m >= 3:\n",
    "        return 'Loyal Customers'\n",
    "    elif r >= 4 and f <= 2 and m <= 2:\n",
    "        return 'New Customers'\n",
    "    elif r <= 2 and f >= 4 and m >= 4:\n",
    "        return 'At Risk'\n",
    "    elif r <= 2 and f <= 2:\n",
    "        return 'Lost'\n",
    "    elif r >= 3 and f <= 2 and m <= 2:\n",
    "        return 'Promising'\n",
    "    elif r <= 2 and f >= 3:\n",
    "        return 'Need Attention'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "rfm['Segment'] = rfm.apply(segment_customers, axis=1)\n",
    "\n",
    "# Segment distribution\n",
    "segment_counts = rfm['Segment'].value_counts()\n",
    "print(\"\\nCustomer Segment Distribution:\")\n",
    "print(segment_counts)\n",
    "\n",
    "# Calculate segment value\n",
    "segment_value = rfm.groupby('Segment').agg({\n",
    "    'CustomerID': 'count',\n",
    "    'Monetary': ['sum', 'mean'],\n",
    "    'Frequency': 'mean',\n",
    "    'Recency': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nSegment Performance Metrics:\")\n",
    "print(segment_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d25494aa-627e-40c6-9395-1b4e273781db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Churn Risk Analysis\n",
      "======================================================================\n",
      "Churn Risk Distribution:\n",
      "Churn_Risk_Category\n",
      "High Risk      1731\n",
      "Medium Risk    1425\n",
      "Low Risk       1182\n",
      "Name: count, dtype: int64\n",
      "\n",
      "High Risk Customers:\n",
      "Count: 1,731\n",
      "Total Revenue at Risk: $1,046,682.67\n"
     ]
    }
   ],
   "source": [
    "# Calculate churn risk based on recency and declining purchase patterns\n",
    "print(\"=\"*70)\n",
    "print(\"Churn Risk Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Merge rfm with customer summary\n",
    "customer_analysis = customer_summary.merge(rfm[['CustomerID', 'Recency', 'Segment', 'RFM_Total']], \n",
    "                                           on='CustomerID')\n",
    "\n",
    "# Calculate churn risk score (0-100, higher = more risk)\n",
    "def calculate_churn_risk(row):\n",
    "    risk_score = 0\n",
    "    \n",
    "    # Recency factor (40% weight)\n",
    "    if row['Recency'] > 180:\n",
    "        risk_score += 40\n",
    "    elif row['Recency'] > 90:\n",
    "        risk_score += 30\n",
    "    elif row['Recency'] > 60:\n",
    "        risk_score += 20\n",
    "    elif row['Recency'] > 30:\n",
    "        risk_score += 10\n",
    "    \n",
    "    # Frequency factor (30% weight)\n",
    "    if row['Total_Orders'] < 5:\n",
    "        risk_score += 30\n",
    "    elif row['Total_Orders'] < 10:\n",
    "        risk_score += 20\n",
    "    elif row['Total_Orders'] < 20:\n",
    "        risk_score += 10\n",
    "    \n",
    "    # RFM score factor (30% weight)\n",
    "    if row['RFM_Total'] < 6:\n",
    "        risk_score += 30\n",
    "    elif row['RFM_Total'] < 9:\n",
    "        risk_score += 20\n",
    "    elif row['RFM_Total'] < 12:\n",
    "        risk_score += 10\n",
    "    \n",
    "    return risk_score\n",
    "\n",
    "customer_analysis['Churn_Risk_Score'] = customer_analysis.apply(calculate_churn_risk, axis=1)\n",
    "\n",
    "# Categorize churn risk\n",
    "def churn_risk_category(score):\n",
    "    if score >= 70:\n",
    "        return 'High Risk'\n",
    "    elif score >= 40:\n",
    "        return 'Medium Risk'\n",
    "    else:\n",
    "        return 'Low Risk'\n",
    "\n",
    "customer_analysis['Churn_Risk_Category'] = customer_analysis['Churn_Risk_Score'].apply(churn_risk_category)\n",
    "\n",
    "print(\"Churn Risk Distribution:\")\n",
    "print(customer_analysis['Churn_Risk_Category'].value_counts())\n",
    "\n",
    "print(\"\\nHigh Risk Customers:\")\n",
    "high_risk = customer_analysis[customer_analysis['Churn_Risk_Category'] == 'High Risk']\n",
    "print(f\"Count: {len(high_risk):,}\")\n",
    "print(f\"Total Revenue at Risk: ${high_risk['Total_Revenue'].sum():,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18b6a85c-0bb5-424e-b852-fdd98d450e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MRR Growth Accounting Analysis\n",
      "======================================================================\n",
      "\n",
      "MRR Type Distribution:\n",
      "MRR_Type\n",
      "New             4338\n",
      "Reactivation    4098\n",
      "Contraction     2449\n",
      "Expansion       2158\n",
      "Retained          11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "MRR Change Breakdown by Type:\n",
      "              Count  Total_MRR_Change    Total_MRR\n",
      "MRR_Type                                          \n",
      "Contraction    2449     -1,640,512.14 1,518,395.64\n",
      "Expansion      2158      1,460,429.15 2,830,495.96\n",
      "New            4338      2,244,830.59 2,244,830.59\n",
      "Reactivation   4098        260,854.65 2,288,099.20\n",
      "Retained         11              0.00     5,387.50\n",
      "\n",
      "Sample Monthly MRR Movement:\n",
      "        Month      MRR_Type  MRR_Change  CustomerID\n",
      "0  2010-12-01           New  570,422.73         885\n",
      "1  2011-01-01   Contraction -124,374.96         180\n",
      "2  2011-01-01     Expansion  100,049.91         144\n",
      "3  2011-01-01           New  292,366.84         417\n",
      "4  2011-02-01   Contraction  -58,091.93         136\n",
      "5  2011-02-01     Expansion   51,292.26         125\n",
      "6  2011-02-01           New  157,700.59         380\n",
      "7  2011-02-01  Reactivation  -24,762.07         116\n",
      "8  2011-02-01      Retained        0.00           1\n",
      "9  2011-03-01   Contraction  -58,330.28         135\n",
      "10 2011-03-01     Expansion   75,950.92         153\n",
      "11 2011-03-01           New  199,619.67         452\n",
      "12 2011-03-01  Reactivation  -23,644.04         232\n",
      "13 2011-03-01      Retained        0.00           2\n",
      "14 2011-04-01   Contraction -156,468.31         167\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MRR GROWTH ACCOUNTING ANALYSIS\n",
    "\n",
    "Purpose: Track how Monthly Recurring Revenue changes month-over-month\n",
    "Categories: New, Expansion, Contraction, Reactivation, Retained\n",
    "\n",
    "Key Concept: Compare each month's MRR to the previous month for the same customer\n",
    "- New: First time seeing this customer (no previous month MRR)\n",
    "- Expansion: Customer's MRR increased (they spent more)\n",
    "- Contraction: Customer's MRR decreased (they spent less)\n",
    "- Reactivation: Customer was gone for 2+ months, now back\n",
    "- Retained: Customer's MRR stayed the same\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MRR Growth Accounting Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Sort data by customer and month (chronological order per customer)\n",
    "# Why: We need to compare each month to the PREVIOUS month for the SAME customer\n",
    "mrr_sorted = mrr_data.sort_values(['CustomerID', 'Month']).reset_index(drop=True)\n",
    "\n",
    "# Step 2: Get previous month's data for each customer\n",
    "# .shift(1) moves each row down by 1, so we can see \"last month\" next to \"this month\"\n",
    "mrr_sorted['Prev_Month'] = mrr_sorted.groupby('CustomerID')['Month'].shift(1)\n",
    "mrr_sorted['Prev_MRR'] = mrr_sorted.groupby('CustomerID')['MRR'].shift(1)\n",
    "\n",
    "# Step 3: Calculate how many months passed since last transaction\n",
    "# Why: If gap > 1 month, customer \"churned\" then came back (Reactivation)\n",
    "# Convert days to months by dividing by 30\n",
    "mrr_sorted['Months_Since_Last'] = ((mrr_sorted['Month'] - mrr_sorted['Prev_Month']).dt.days / 30).round()\n",
    "\n",
    "# Step 4: Categorize each transaction based on MRR change\n",
    "def categorize_mrr_change(row):\n",
    "    # No previous MRR? This is their first month (New customer)\n",
    "    if pd.isna(row['Prev_MRR']):\n",
    "        return 'New'\n",
    "    \n",
    "    # Gap of 2+ months? They were gone, now back (Reactivation)\n",
    "    elif row['Months_Since_Last'] > 1:\n",
    "        return 'Reactivation'\n",
    "    \n",
    "    # MRR went up? Expansion (upgrade/increased usage)\n",
    "    elif row['MRR'] > row['Prev_MRR']:\n",
    "        return 'Expansion'\n",
    "    \n",
    "    # MRR went down? Contraction (downgrade/decreased usage)\n",
    "    elif row['MRR'] < row['Prev_MRR']:\n",
    "        return 'Contraction'\n",
    "    \n",
    "    # MRR stayed same? Retained (stable customer)\n",
    "    else:\n",
    "        return 'Retained'\n",
    "\n",
    "# Apply the categorization to each row\n",
    "mrr_sorted['MRR_Type'] = mrr_sorted.apply(categorize_mrr_change, axis=1)\n",
    "\n",
    "# Step 5: Calculate the dollar amount of MRR change\n",
    "# If Prev_MRR is NaN (new customer), treat it as 0\n",
    "mrr_sorted['MRR_Change'] = mrr_sorted['MRR'] - mrr_sorted['Prev_MRR'].fillna(0)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nMRR Type Distribution:\")\n",
    "print(mrr_sorted['MRR_Type'].value_counts())\n",
    "\n",
    "print(\"\\nMRR Change Breakdown by Type:\")\n",
    "mrr_summary = mrr_sorted.groupby('MRR_Type').agg({\n",
    "    'CustomerID': 'count',      # How many transactions in each category\n",
    "    'MRR_Change': 'sum',         # Total dollar change\n",
    "    'MRR': 'sum'                 # Total MRR\n",
    "}).round(2)\n",
    "mrr_summary.columns = ['Count', 'Total_MRR_Change', 'Total_MRR']\n",
    "print(mrr_summary)\n",
    "\n",
    "# Step 6: Monthly MRR movement (see trends over time)\n",
    "monthly_mrr_movement = mrr_sorted.groupby(['Month', 'MRR_Type']).agg({\n",
    "    'MRR_Change': 'sum',\n",
    "    'CustomerID': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "print(\"\\nSample Monthly MRR Movement:\")\n",
    "print(monthly_mrr_movement.head(15))\n",
    "\n",
    "# Save for later use\n",
    "mrr_with_changes = mrr_sorted.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c262bb35-155e-4c1f-b892-05f04885b8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Generating Synthetic Support Tickets Data\n",
      "======================================================================\n",
      "\n",
      "Total Support Tickets Generated: 13,854\n",
      "Customers with Tickets: 3,566\n",
      "\n",
      "Tickets by Segment:\n",
      "Segment\n",
      "Lost               3452\n",
      "Champions          3053\n",
      "Loyal Customers    2495\n",
      "Need Attention     1466\n",
      "Others             1388\n",
      "New Customers       771\n",
      "Promising           713\n",
      "At Risk             516\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ticket Type Distribution:\n",
      "TicketType\n",
      "Technical Issue     6006\n",
      "Billing Question    3830\n",
      "Account Access      2627\n",
      "Product Training     709\n",
      "Feature Request      682\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment Distribution:\n",
      "Sentiment\n",
      "Negative    7373\n",
      "Neutral     4433\n",
      "Positive    2048\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample Tickets:\n",
      "   TicketID  CustomerID    CreatedTimestamp        TicketType Sentiment  \\\n",
      "0         1   12,346.00 2011-01-18 10:01:00    Account Access  Negative   \n",
      "1         2   12,347.00 2011-03-23 14:57:00  Billing Question  Negative   \n",
      "2         3   12,347.00 2011-04-07 14:57:00   Technical Issue  Positive   \n",
      "3         4   12,347.00 2011-03-04 14:57:00   Technical Issue   Neutral   \n",
      "4         5   12,347.00 2011-04-16 14:57:00   Technical Issue  Negative   \n",
      "5         6   12,347.00 2011-09-26 14:57:00   Technical Issue  Negative   \n",
      "6         7   12,347.00 2011-05-16 14:57:00   Technical Issue  Negative   \n",
      "7         8   12,348.00 2011-08-08 19:09:00   Technical Issue  Positive   \n",
      "8         9   12,348.00 2011-02-12 19:09:00  Billing Question  Positive   \n",
      "9        10   12,349.00 2011-11-21 09:51:00    Account Access   Neutral   \n",
      "\n",
      "     Segment  \n",
      "0       Lost  \n",
      "1  Champions  \n",
      "2  Champions  \n",
      "3  Champions  \n",
      "4  Champions  \n",
      "5  Champions  \n",
      "6  Champions  \n",
      "7    At Risk  \n",
      "8    At Risk  \n",
      "9     Others  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "SYNTHETIC DATA GENERATION: SUPPORT TICKETS\n",
    "=============================================================================\n",
    "\n",
    "Purpose: Generate realistic customer support ticket data that matches\n",
    "         the existing PostgreSQL table structure used in Power BI dashboards\n",
    "\n",
    "Table Structure (PostgreSQL): supporttickets\n",
    "Columns: TicketID, CustomerID, CreatedTimestamp, TicketType, Sentiment, Segment\n",
    "\n",
    "Correlation Strategy:\n",
    "- Customers with declining revenue trends → More tickets + Negative sentiment\n",
    "- High churn risk customers → More support interactions\n",
    "- Different RFM segments → Different ticket patterns and sentiments\n",
    "\n",
    "This demonstrates:\n",
    "1. Consistent data schema across pipeline (Python → CSV → PostgreSQL → Power BI)\n",
    "2. Business logic correlation (support behavior linked to customer health)\n",
    "3. Synthetic data generation with realistic distributions\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Generating Synthetic Support Tickets Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Get customer data with segments and revenue trends\n",
    "# Merge customer_analysis with revenue trend calculation\n",
    "customer_revenue_trends = df_clean.groupby('CustomerID').apply(\n",
    "    lambda x: (x.sort_values('InvoiceDate')['Revenue'].iloc[-1] - \n",
    "               x.sort_values('InvoiceDate')['Revenue'].iloc[0]) \n",
    "              if len(x) > 1 else 0\n",
    ").reset_index()\n",
    "customer_revenue_trends.columns = ['CustomerID', 'Revenue_Trend']\n",
    "\n",
    "support_base = customer_analysis[['CustomerID', 'Segment']].merge(\n",
    "    customer_revenue_trends, on='CustomerID', how='left'\n",
    ")\n",
    "\n",
    "# Step 2: Define ticket generation rules based on revenue trends\n",
    "# Declining revenue = more tickets (struggling customers need help)\n",
    "def generate_ticket_count(revenue_trend):\n",
    "    \"\"\"\n",
    "    Determine number of tickets based on customer revenue trend\n",
    "    Declining revenue = more support issues\n",
    "    Growing revenue = fewer support issues\n",
    "    \"\"\"\n",
    "    if revenue_trend < 0:      # Revenue declining\n",
    "        return np.random.randint(3, 10)\n",
    "    elif revenue_trend == 0:    # Stable\n",
    "        return np.random.randint(1, 4)\n",
    "    else:                       # Revenue growing\n",
    "        return np.random.randint(0, 3)\n",
    "\n",
    "# Apply ticket count generation\n",
    "support_base['Ticket_Count'] = support_base['Revenue_Trend'].fillna(0).apply(generate_ticket_count)\n",
    "\n",
    "# Step 3: Create individual ticket records\n",
    "ticket_records = []\n",
    "\n",
    "# Ticket types realistic to SaaS businesses (matching your original)\n",
    "ticket_types = ['Technical Issue', 'Billing Question', 'Feature Request', \n",
    "                'Account Access', 'Product Training']\n",
    "\n",
    "# Sentiment categories (matching PostgreSQL table)\n",
    "sentiments = ['Positive', 'Neutral', 'Negative']\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Step 4: Generate tickets for each customer\n",
    "ticket_id_counter = 1\n",
    "\n",
    "for idx, row in support_base.iterrows():\n",
    "    customer_id = row['CustomerID']\n",
    "    ticket_count = row['Ticket_Count']\n",
    "    revenue_trend = row['Revenue_Trend']\n",
    "    segment = row['Segment']\n",
    "    \n",
    "    # Generate multiple tickets per customer\n",
    "    for i in range(ticket_count):\n",
    "        # Random ticket date within customer's active period\n",
    "        customer_dates = df_clean[df_clean['CustomerID'] == customer_id]['InvoiceDate']\n",
    "        if len(customer_dates) > 0:\n",
    "            min_date = customer_dates.min()\n",
    "            max_date = customer_dates.max()\n",
    "            days_range = (max_date - min_date).days\n",
    "            if days_range > 0:\n",
    "                ticket_date = min_date + pd.Timedelta(days=np.random.randint(0, days_range))\n",
    "            else:\n",
    "                ticket_date = min_date\n",
    "        else:\n",
    "            ticket_date = pd.Timestamp('2011-06-01')\n",
    "        \n",
    "        # Ticket type weighted by revenue trend and segment\n",
    "        if revenue_trend < 0:  # Declining revenue\n",
    "            # More likely to have technical issues and billing questions\n",
    "            ticket_type = np.random.choice(\n",
    "                ['Technical Issue', 'Billing Question', 'Account Access'],\n",
    "                p=[0.5, 0.3, 0.2]\n",
    "            )\n",
    "            # Negative sentiment for struggling customers\n",
    "            sentiment = np.random.choice(sentiments, p=[0.1, 0.3, 0.6])\n",
    "        elif segment in ['Champions', 'Loyal']:\n",
    "            # High-value customers: feature requests, positive sentiment\n",
    "            ticket_type = np.random.choice(['Feature Request', 'Product Training'])\n",
    "            sentiment = np.random.choice(sentiments, p=[0.6, 0.3, 0.1])\n",
    "        else:\n",
    "            # Random distribution for others\n",
    "            ticket_type = np.random.choice(ticket_types)\n",
    "            sentiment = np.random.choice(sentiments, p=[0.3, 0.4, 0.3])\n",
    "        \n",
    "        # Create ticket record (EXACT column names matching PostgreSQL)\n",
    "        ticket_records.append({\n",
    "            'TicketID': ticket_id_counter,\n",
    "            'CustomerID': customer_id,\n",
    "            'CreatedTimestamp': ticket_date,\n",
    "            'TicketType': ticket_type,\n",
    "            'Sentiment': sentiment,\n",
    "            'Segment': segment\n",
    "        })\n",
    "        \n",
    "        ticket_id_counter += 1\n",
    "\n",
    "# Step 5: Create tickets dataframe\n",
    "support_tickets = pd.DataFrame(ticket_records)\n",
    "\n",
    "# Display summary\n",
    "print(f\"\\nTotal Support Tickets Generated: {len(support_tickets):,}\")\n",
    "print(f\"Customers with Tickets: {support_tickets['CustomerID'].nunique():,}\")\n",
    "\n",
    "print(\"\\nTickets by Segment:\")\n",
    "print(support_tickets['Segment'].value_counts())\n",
    "\n",
    "print(\"\\nTicket Type Distribution:\")\n",
    "print(support_tickets['TicketType'].value_counts())\n",
    "\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(support_tickets['Sentiment'].value_counts())\n",
    "\n",
    "print(\"\\nSample Tickets:\")\n",
    "print(support_tickets.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4df7dacb-21bf-4dc1-8dba-3d575aa2d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Generating Synthetic Usage Logs Data\n",
      "======================================================================\n",
      "\n",
      "Total Usage Logs Generated: 9,481\n",
      "Customers with Activity: 3,241\n",
      "\n",
      "Usage by Segment:\n",
      "Segment\n",
      "Champions          5040\n",
      "Loyal Customers    1426\n",
      "Lost               1092\n",
      "Need Attention      529\n",
      "At Risk             448\n",
      "Others              442\n",
      "Promising           259\n",
      "New Customers       245\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Event Type Distribution:\n",
      "EventType\n",
      "Login               3279\n",
      "Dashboard View      1982\n",
      "Report Generated    1500\n",
      "Data Export         1220\n",
      "Settings Updated     920\n",
      "Profile View         580\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Session Duration Stats:\n",
      "count   9,481.00\n",
      "mean       29.12\n",
      "std        16.23\n",
      "min         2.00\n",
      "25%        16.00\n",
      "50%        27.00\n",
      "75%        43.00\n",
      "max        59.00\n",
      "Name: SessionDuration, dtype: float64\n",
      "\n",
      "Sample Usage Logs:\n",
      "   LogID  CustomerID      EventTimestamp       EventType  SessionDuration\n",
      "0      1   12,347.00 2011-03-19 14:57:00     Data Export               29\n",
      "1      2   12,347.00 2011-03-23 14:57:00     Data Export               35\n",
      "2      3   12,348.00 2011-03-28 19:09:00           Login                8\n",
      "3      4   12,348.00 2011-03-13 19:09:00           Login                9\n",
      "4      5   12,348.00 2011-05-16 19:09:00           Login                6\n",
      "5      6   12,348.00 2011-08-30 19:09:00  Dashboard View                7\n",
      "6      7   12,348.00 2011-06-25 19:09:00  Dashboard View                2\n",
      "7      8   12,348.00 2011-01-06 19:09:00           Login               10\n",
      "8      9   12,349.00 2011-11-21 09:51:00           Login               14\n",
      "9     10   12,350.00 2011-02-02 16:01:00           Login               13\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "SYNTHETIC DATA GENERATION: USAGE LOGS\n",
    "=============================================================================\n",
    "\n",
    "Purpose: Generate realistic product usage/activity data that matches\n",
    "         the existing PostgreSQL table structure used in Power BI dashboards\n",
    "\n",
    "Table Structure (PostgreSQL): usagelogs\n",
    "Columns: LogID, CustomerID, EventTimestamp, EventType, SessionDuration\n",
    "\n",
    "Correlation Strategy:\n",
    "- Purchase frequency → Login frequency (active buyers = active users)\n",
    "- RFM segment → Usage patterns:\n",
    "  * Champions/Loyal: High login frequency, longer sessions\n",
    "  * At Risk/Lost: Low login frequency, shorter sessions\n",
    "  * New: Moderate frequency, learning behavior\n",
    "\n",
    "This demonstrates:\n",
    "1. Behavioral correlation (engagement drives revenue)\n",
    "2. Realistic usage patterns by customer lifecycle stage\n",
    "3. Time-series event generation\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Generating Synthetic Usage Logs Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Calculate purchase frequency for each customer\n",
    "# More purchases = more engaged = more logins\n",
    "purchase_frequency = df_clean.groupby('CustomerID').agg({\n",
    "    'InvoiceNo': 'nunique',\n",
    "    'InvoiceDate': ['min', 'max']\n",
    "}).reset_index()\n",
    "purchase_frequency.columns = ['CustomerID', 'Purchase_Count', 'First_Purchase', 'Last_Purchase']\n",
    "\n",
    "# Merge with segment data\n",
    "usage_base = customer_analysis[['CustomerID', 'Segment']].merge(\n",
    "    purchase_frequency, on='CustomerID', how='left'\n",
    ")\n",
    "\n",
    "# Step 2: Define login generation rules based on purchase frequency\n",
    "# Active buyers = active users (correlated behavior)\n",
    "def generate_login_count(purchase_count):\n",
    "    \"\"\"\n",
    "    Determine number of logins based on purchase frequency\n",
    "    More purchases = more platform engagement\n",
    "    Use Poisson distribution for realistic variance\n",
    "    \"\"\"\n",
    "    avg_logins_per_month = max(1, int(purchase_count / 2))\n",
    "    return np.random.poisson(avg_logins_per_month)\n",
    "\n",
    "# Apply login count generation\n",
    "usage_base['Login_Count'] = usage_base['Purchase_Count'].fillna(1).apply(generate_login_count)\n",
    "\n",
    "# Step 3: Create individual usage log records\n",
    "usage_records = []\n",
    "\n",
    "# Event types realistic to SaaS platform usage\n",
    "event_types = ['Login', 'Dashboard View', 'Report Generated', \n",
    "               'Data Export', 'Settings Updated', 'Profile View']\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Step 4: Generate usage logs for each customer\n",
    "log_id_counter = 1\n",
    "\n",
    "for idx, row in usage_base.iterrows():\n",
    "    customer_id = row['CustomerID']\n",
    "    login_count = row['Login_Count']\n",
    "    segment = row['Segment']\n",
    "    first_date = row['First_Purchase']\n",
    "    last_date = row['Last_Purchase']\n",
    "    \n",
    "    # Generate multiple login events per customer\n",
    "    for i in range(login_count):\n",
    "        # Random event date within customer's active period\n",
    "        if pd.notna(first_date) and pd.notna(last_date):\n",
    "            days_range = (last_date - first_date).days\n",
    "            if days_range > 0:\n",
    "                event_date = first_date + pd.Timedelta(days=np.random.randint(0, days_range))\n",
    "            else:\n",
    "                event_date = first_date\n",
    "        else:\n",
    "            event_date = pd.Timestamp('2011-06-01')\n",
    "        \n",
    "        # Event type weighted by segment\n",
    "        # Champions/Loyal use advanced features more\n",
    "        if segment in ['Champions', 'Loyal Customers']:\n",
    "            event_type = np.random.choice(event_types, p=[0.3, 0.2, 0.2, 0.15, 0.1, 0.05])\n",
    "            # Longer sessions for engaged users\n",
    "            session_duration = np.random.randint(15, 60)\n",
    "        elif segment in ['At Risk', 'Lost']:\n",
    "            # At-risk users mostly just login, short sessions\n",
    "            event_type = np.random.choice(['Login', 'Dashboard View'], p=[0.7, 0.3])\n",
    "            session_duration = np.random.randint(2, 15)\n",
    "        else:\n",
    "            # Average usage for others\n",
    "            event_type = np.random.choice(event_types)\n",
    "            session_duration = np.random.randint(5, 30)\n",
    "        \n",
    "        # Create usage log record (EXACT column names matching PostgreSQL)\n",
    "        usage_records.append({\n",
    "            'LogID': log_id_counter,\n",
    "            'CustomerID': customer_id,\n",
    "            'EventTimestamp': event_date,\n",
    "            'EventType': event_type,\n",
    "            'SessionDuration': session_duration\n",
    "        })\n",
    "        \n",
    "        log_id_counter += 1\n",
    "\n",
    "# Step 5: Create usage logs dataframe\n",
    "usage_logs = pd.DataFrame(usage_records)\n",
    "\n",
    "# Display summary\n",
    "print(f\"\\nTotal Usage Logs Generated: {len(usage_logs):,}\")\n",
    "print(f\"Customers with Activity: {usage_logs['CustomerID'].nunique():,}\")\n",
    "\n",
    "print(\"\\nUsage by Segment:\")\n",
    "usage_by_segment = usage_logs.merge(\n",
    "    customer_analysis[['CustomerID', 'Segment']], \n",
    "    on='CustomerID'\n",
    ")\n",
    "print(usage_by_segment['Segment'].value_counts())\n",
    "\n",
    "print(\"\\nEvent Type Distribution:\")\n",
    "print(usage_logs['EventType'].value_counts())\n",
    "\n",
    "print(\"\\nSession Duration Stats:\")\n",
    "print(usage_logs['SessionDuration'].describe())\n",
    "\n",
    "print(\"\\nSample Usage Logs:\")\n",
    "print(usage_logs.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a88afcdb-3fc2-4a1b-9359-9aef483beabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Exporting All Datasets to CSV\n",
      "======================================================================\n",
      "\n",
      "1. Exporting Cleaned Transactions...\n",
      "   Saved: 392,692 rows -> saas_cleaned_transactions.csv\n",
      "\n",
      "2. Exporting MRR Subscriptions...\n",
      "   Saved: 13,054 rows -> saas_mrr_subscriptions.csv\n",
      "\n",
      "3. Exporting Customer Analysis...\n",
      "   Saved: 4,338 rows -> saas_customer_analysis.csv\n",
      "\n",
      "4. Exporting Support Tickets...\n",
      "   Saved: 13,854 rows -> saas_support_tickets.csv\n",
      "\n",
      "5. Exporting Usage Logs...\n",
      "   Saved: 9,481 rows -> saas_usage_logs.csv\n",
      "\n",
      "======================================================================\n",
      "Export Complete!\n",
      "======================================================================\n",
      "\n",
      "All files saved to current directory with 'saas_' prefix\n",
      "\n",
      "Files created:\n",
      "  - saas_cleaned_transactions.csv\n",
      "  - saas_mrr_subscriptions.csv\n",
      "  - saas_customer_analysis.csv\n",
      "  - saas_support_tickets.csv\n",
      "  - saas_usage_logs.csv\n",
      "\n",
      "Note: Files match PostgreSQL table schemas for direct import\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "DATA EXPORT: Save All Processed Datasets to CSV\n",
    "=============================================================================\n",
    "\n",
    "Purpose: Export all cleaned and generated datasets for documentation\n",
    "         This demonstrates the complete data pipeline from raw to processed\n",
    "\n",
    "File Naming Convention: saas_*.csv\n",
    "- Matches existing production file naming\n",
    "- Shows complete transformation process\n",
    "- Same schema as PostgreSQL tables for consistency\n",
    "\n",
    "Output Files:\n",
    "1. saas_cleaned_transactions.csv - Cleaned retail data\n",
    "2. saas_mrr_subscriptions.csv - Monthly subscription revenue\n",
    "3. saas_customer_analysis.csv - RFM + Churn analysis\n",
    "4. saas_support_tickets.csv - Synthetic support data\n",
    "5. saas_usage_logs.csv - Synthetic usage data\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Exporting All Datasets to CSV\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Export 1: Cleaned Transactions\n",
    "print(\"\\n1. Exporting Cleaned Transactions...\")\n",
    "df_clean.to_csv('saas_cleaned_transactions.csv', index=False)\n",
    "print(f\"   Saved: {len(df_clean):,} rows -> saas_cleaned_transactions.csv\")\n",
    "\n",
    "# Export 2: MRR Subscriptions\n",
    "print(\"\\n2. Exporting MRR Subscriptions...\")\n",
    "mrr_data.to_csv('saas_mrr_subscriptions.csv', index=False)\n",
    "print(f\"   Saved: {len(mrr_data):,} rows -> saas_mrr_subscriptions.csv\")\n",
    "\n",
    "# Export 3: Customer Analysis\n",
    "print(\"\\n3. Exporting Customer Analysis...\")\n",
    "customer_analysis.to_csv('saas_customer_analysis.csv', index=False)\n",
    "print(f\"   Saved: {len(customer_analysis):,} rows -> saas_customer_analysis.csv\")\n",
    "\n",
    "# Export 4: Support Tickets\n",
    "print(\"\\n4. Exporting Support Tickets...\")\n",
    "support_tickets.to_csv('saas_support_tickets.csv', index=False)\n",
    "print(f\"   Saved: {len(support_tickets):,} rows -> saas_support_tickets.csv\")\n",
    "\n",
    "# Export 5: Usage Logs\n",
    "print(\"\\n5. Exporting Usage Logs...\")\n",
    "usage_logs.to_csv('saas_usage_logs.csv', index=False)\n",
    "print(f\"   Saved: {len(usage_logs):,} rows -> saas_usage_logs.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Export Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nAll files saved to current directory with 'saas_' prefix\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"  - saas_cleaned_transactions.csv\")\n",
    "print(\"  - saas_mrr_subscriptions.csv\")\n",
    "print(\"  - saas_customer_analysis.csv\")\n",
    "print(\"  - saas_support_tickets.csv\")\n",
    "print(\"  - saas_usage_logs.csv\")\n",
    "\n",
    "print(\"\\nNote: Files match PostgreSQL table schemas for direct import\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7787e-7648-4b60-b0f1-efafafcd14f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
